in readme.md, correct the path to example.log
in sample yaml should be -output (- fails)
the generated AI examples are all false!
the first ai test is the public test
when iterating on ai tests, it is asked to correct the flow, but the original flow is not given

it seems to generate too many functions, but it is easier to test.
The functions inputs can't be generated by AI, because they may have constraints that are not easy for LLM to generate.

idea: add import in functions, so it does not forget it.

in runing in AI input, it can be asked to check if implementation matches the part of algo.
Also if argument is not valid, the calling function should be corrected.

TODO global code in main()

It seems public tests reasoning is disabled. why not to emable it?

generate_ai_tests
  how chatGPT can create long inputs?
  #FIXME adding public tests to the beginning and end of the list: But AI tests have no output!

run_generate_possible_solutions.python
   remove_bruce_force_solutions is set to true (in upstream), but we instructed LLM to generate it if no better solution.

run_choose_best_solution
    when generating the solutions, LLM automatically generates numbered steps (we can explicitly ask it to do so). it seems when choosing the best one, it simply copy-pastes it. so flow is not necessary.